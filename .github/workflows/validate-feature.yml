name: Validate Feature Guide

on:
  push:
    paths:
      - '**/validation/validation-payload.json'
  workflow_dispatch:
    inputs:
      feature_folder:
        description: 'Feature folder to validate (e.g., overtime/v1)'
        required: true
      debug_mode:
        description: 'Enable debug logging'
        required: false
        default: 'false'

env:
  PLAYWRIGHT_MCP_SERVER: "@executeautomation/playwright-mcp-server"
  NODE_VERSION: "20"

jobs:
  validate:
    runs-on: [self-hosted, validation]
    timeout-minutes: 60

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 2
          persist-credentials: false

      - name: Detect validation payload
        id: detect
        run: |
          if [ -n "${{ github.event.inputs.feature_folder }}" ]; then
            FOLDER="${{ github.event.inputs.feature_folder }}"
          else
            CHANGED_FILE=$(git diff --name-only HEAD~1 HEAD | grep 'validation/validation-payload.json' | head -1)
            if [ -n "$CHANGED_FILE" ]; then
              FOLDER=$(echo "$CHANGED_FILE" | sed 's|/validation/.*||')
            fi
          fi

          if [ -z "$FOLDER" ]; then
            echo "No validation request found"
            echo "skip=true" >> $GITHUB_OUTPUT
            exit 0
          fi

          PAYLOAD_FILE="$GITHUB_WORKSPACE/$FOLDER/validation/validation-payload.json"
          if [ ! -f "$PAYLOAD_FILE" ]; then
            echo "Payload file not found: $PAYLOAD_FILE"
            echo "skip=true" >> $GITHUB_OUTPUT
            exit 0
          fi

          echo "folder=$FOLDER" >> $GITHUB_OUTPUT
          echo "payload_file=$PAYLOAD_FILE" >> $GITHUB_OUTPUT
          echo "skip=false" >> $GITHUB_OUTPUT

          # Extract feature info (supports object format with .feature_info)
          FEATURE_NAME=$(jq -r '.feature_info.feature_name // .metadata.feature_name // "unknown"' "$PAYLOAD_FILE")
          FEATURE_SLUG=$(jq -r '.feature_info.feature_slug // .metadata.feature_slug // "unknown"' "$PAYLOAD_FILE")
          VERSION=$(jq -r '.feature_info.next_version // .metadata.version // "v1"' "$PAYLOAD_FILE")

          echo "feature_name=$FEATURE_NAME" >> $GITHUB_OUTPUT
          echo "feature_slug=$FEATURE_SLUG" >> $GITHUB_OUTPUT
          echo "version=$VERSION" >> $GITHUB_OUTPUT

      - name: Setup directories
        id: dirs
        if: steps.detect.outputs.skip != 'true'
        run: |
          FOLDER="${{ steps.detect.outputs.folder }}"
          BASE_DIR="$GITHUB_WORKSPACE/$FOLDER/validation"

          # Create all output directories
          mkdir -p "$BASE_DIR/screenshots"
          mkdir -p "$BASE_DIR/results"
          mkdir -p "$BASE_DIR/logs"
          mkdir -p "$BASE_DIR/artifacts"

          # Output paths for later steps
          echo "base_dir=$BASE_DIR" >> $GITHUB_OUTPUT
          echo "screenshots_dir=$BASE_DIR/screenshots" >> $GITHUB_OUTPUT
          echo "results_dir=$BASE_DIR/results" >> $GITHUB_OUTPUT
          echo "logs_dir=$BASE_DIR/logs" >> $GITHUB_OUTPUT
          echo "result_file=$BASE_DIR/result.json" >> $GITHUB_OUTPUT
          echo "report_file=$BASE_DIR/report.md" >> $GITHUB_OUTPUT
          echo "log_file=$BASE_DIR/logs/validation.log" >> $GITHUB_OUTPUT

          echo "Output directories created:"
          echo "  Screenshots: $BASE_DIR/screenshots"
          echo "  Results: $BASE_DIR/results"
          echo "  Logs: $BASE_DIR/logs"
          echo "  Artifacts: $BASE_DIR/artifacts"

      - name: Setup Node.js
        if: steps.detect.outputs.skip != 'true'
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install Playwright MCP
        if: steps.detect.outputs.skip != 'true'
        run: npm install -g ${{ env.PLAYWRIGHT_MCP_SERVER }}

      - name: Run Playwright Validation
        if: steps.detect.outputs.skip != 'true'
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          APP_BASE_URL: ${{ secrets.APP_BASE_URL }}
          APP_USERNAME: ${{ secrets.APP_USERNAME }}
          APP_PASSWORD: ${{ secrets.APP_PASSWORD }}
        run: |
          FOLDER="${{ steps.detect.outputs.folder }}"
          PAYLOAD_FILE="${{ steps.detect.outputs.payload_file }}"
          FEATURE_NAME="${{ steps.detect.outputs.feature_name }}"
          SCREENSHOTS_DIR="${{ steps.dirs.outputs.screenshots_dir }}"
          RESULT_FILE="${{ steps.dirs.outputs.result_file }}"
          LOG_FILE="${{ steps.dirs.outputs.log_file }}"

          # Create the prompt file
          PROMPT_FILE=$(mktemp)
          cat > "$PROMPT_FILE" << 'PROMPT_HEADER'
          You are a QA validation agent using Playwright MCP to explore and validate a feature in the Bayzat HR application.
          Your output will be used to generate user guides, so document EVERYTHING you see and experience.

          ## YOUR MISSION
          Execute the validation steps defined in the payload below. The payload contains:
          - `execution_order`: The sequence of steps to follow
          - `exploration_phase`: Instructions for UI discovery
          - `primary_entity`: How to identify and test the main entity (CRUD operations)
          - `workflow_exploration`: How to check for workflow integrations
          - `approval_flow_exploration`: How to check for approval flows
          - `what_to_do`: Specific validation tasks
          - `what_to_watch_out_for`: Constraints and limitations to validate

          ## PHASE 0: BROWSER SETUP & LOGIN

          ### Step 0.1: Initialize Browser
          1. Call browser_navigate with url from CREDENTIALS section (Base URL)
          2. Call browser_resize with width=1280 and height=900
          3. Call browser_wait_for with time=6 (allow page to fully render - React apps need extra time)

          ### Step 0.2: Login (OPTIMIZED - USE browser_fill_form)

          **CRITICAL: Use browser_fill_form to fill BOTH fields in ONE call. This is faster and more reliable.**

          1. Call browser_snapshot to see the login page structure
             - Look for element refs for: Email field, Password field, Log in button
             - Note the exact refs (e.g., "S1E3", "S1E5", "S1E8")
             - If snapshot shows no refs or undefined, wait 3 seconds and retry

          2. Call browser_fill_form with fields array containing BOTH email and password:
             fields: [
               { "name": "Email", "type": "textbox", "ref": "[email-field-ref]", "value": "[username from CREDENTIALS]" },
               { "name": "Password", "type": "textbox", "ref": "[password-field-ref]", "value": "[password from CREDENTIALS]" }
             ]

          3. Call browser_click with the Log in button ref

          4. Call browser_wait_for with time=8 (allow dashboard to fully load - this is critical!)

          5. Call browser_snapshot to verify you're on the dashboard
             - Success indicator: You should see sidebar items like "Home", "Company", "People", etc.
             - If still on login page, go to RETRY LOGIC below

          **LOGIN RETRY LOGIC (if first attempt fails):**
          - Wait 5 more seconds: browser_wait_for with time=5
          - Take another snapshot to check state
          - If still on login page with empty fields:
            a. Re-snapshot to get fresh refs
            b. Use browser_fill_form again with new refs
            c. Click login button
            d. Wait 8 seconds
          - If still failing after 2 retries, document the error and proceed to output JSON

          **COMMON LOGIN ISSUES AND SOLUTIONS:**
          - "Snapshot shows undefined refs" → Wait longer (5-10 sec) and retry snapshot
          - "Fields don't accept input" → React not hydrated, wait and retry
          - "Login button click has no effect" → Page not ready, wait and retry
          - "Invalid credentials error" → Verify CREDENTIALS values are correct

          ### Step 0.3: Dismiss Onboarding Tours (CLICK-BASED - NOT JavaScript!)

          **CRITICAL: browser_evaluate often returns undefined. Use CLICK-BASED dismissal instead!**

          After successful login, tour popovers may appear. Dismiss them using clicks:

          1. Call browser_snapshot to see if any tour/popover elements are visible

          2. Look for these tour indicators in the snapshot:
             - Elements with text "Got it", "Next", "Skip", "Close", "Dismiss"
             - X or close icons (usually in top-right of popover)
             - Buttons with data-external-id containing "close" or "confirm"
             - Overlay/backdrop elements

          3. If tour elements found, click the dismiss button:
             - Call browser_click with the ref of the dismiss/close/Got it button
             - Call browser_wait_for with time=2
             - Call browser_snapshot to check if dismissed

          4. Repeat steps 2-3 until no more tour popovers visible (max 5 iterations)

          5. If tours persist after 5 attempts:
             - Try pressing Escape key: browser_press_key with key="Escape"
             - Try clicking outside the popover on the main content area
             - Document that tours could not be dismissed and continue

          **WHY NOT JavaScript?** The browser_evaluate function often returns undefined in this environment,
          making localStorage and JS-based dismissal unreliable. Click-based dismissal works consistently.

          **TOUR ELEMENT PATTERNS TO LOOK FOR:**
          - "Got it" button (most common)
          - "Skip tour" link
          - "X" close icon in popover header
          - "Next" / "Finish" buttons (click through the tour)
          - Elements with class containing "tour", "walkthrough", "onboarding", "popover"

          ### Step 0.4: Verify Session is Active

          Before proceeding to feature exploration:
          1. Call browser_snapshot
          2. Verify you see the main dashboard/sidebar
          3. If you see the login page instead, the session was lost - retry login
          4. Take a screenshot of the clean dashboard state

          ---

          ## PHASE 1: EXECUTE PAYLOAD INSTRUCTIONS

          **CRITICAL: Follow the `execution_order` array from the payload sequentially.**

          For each step in `execution_order`, use the corresponding payload section:

          ### When execution_order says "EXPLORATION":
          Read and execute each instruction in `exploration_phase.instructions[]`:
          - Navigate to the feature's main section by CLICKING sidebar menu items
          - Take snapshots to understand layout
          - Find all clickable elements
          - Map navigation structure
          - Click each tab/sub-section
          - Document modals, dialogs, panels
          - Identify form fields and input types
          - Look for filters, search, sort, export options

          Use `exploration_phase.discovery_targets[]` as your checklist of things to find.

          ### When execution_order says "IDENTIFY ENTITY":
          Read and execute `primary_entity.discovery_instructions[]`:
          - Identify what the main item/entity is (ticket, workflow, employee, etc.)
          - Look for list/table views - rows represent the primary entity
          - Check page headers and breadcrumbs for entity naming
          - Note singular and plural forms used in the UI

          ### When execution_order says "CRUD TEST":
          Test each operation in `primary_entity.crud_operations`:

          **CREATE:**
          - Use `crud_operations.create.find_trigger[]` to locate the create button
          - Look for: + Add, + Create, + New, plus icon, top-right corner, FAB, empty state prompts
          - Validate: `crud_operations.create.validation`

          **READ:**
          - Use `crud_operations.read.find_trigger[]` to view item details
          - Look for: clickable rows, View button, eye icon
          - Validate: `crud_operations.read.validation`

          **UPDATE:**
          - Use `crud_operations.update.find_trigger[]` to edit items
          - Look for: Edit button, pencil icon, inline editing, status dropdowns, three-dot menu
          - Validate: `crud_operations.update.validation`

          **DELETE:**
          - Use `crud_operations.delete.find_trigger[]` to remove items
          - Look for: Delete button, trash icon, three-dot menu, bulk delete, Archive/Cancel alternatives
          - Validate: `crud_operations.delete.validation`

          ### When execution_order says "WORKFLOW CHECK":
          **Only if `workflow_exploration.enabled` is true:**

          Read and execute `workflow_exploration.check_instructions[]`:
          - Navigate to: `workflow_exploration.nav_path` (Automations -> Workflows -> + Create workflow)
          - In trigger selection, search for this feature's name
          - Check if feature appears as trigger source
          - Document trigger events found (e.g., 'item created', 'status changed')
          - Check Actions section for feature-related actions
          - Screenshot available triggers and actions

          Priority: `workflow_exploration.priority` (required = must do, optional = if time permits)

          ### When execution_order says "APPROVAL FLOW":
          **Only if `approval_flow_exploration.enabled` is true:**

          Read and execute `approval_flow_exploration.check_instructions[]`:
          - Look for 'Approval' or 'Pending Approval' status
          - Check for approval workflow indicators
          - Look for 'Submit for Approval' buttons
          - Find approval settings in configuration
          - Document the approval chain
          - Check for approval history/audit trail

          Use `approval_flow_exploration.detection_signals[]` to identify approval UI:
          - Status dropdown with 'Pending Approval' option
          - Approve/Reject buttons
          - Approval history section
          - 'Requires approval' toggle in settings
          - Approver assignment fields

          Priority: `approval_flow_exploration.priority`

          ### When execution_order says "WHAT_TO_DO":
          Execute each task in the `what_to_do[]` array from the payload.
          For each task:
          1. Navigate to the relevant section
          2. Perform the described action
          3. Document the result
          4. Take screenshot as evidence

          ### When execution_order says "WHAT_TO_WATCH_OUT_FOR":
          **CRITICAL: Validate each constraint in `what_to_watch_out_for[]` array.**

          For each item:
          1. Understand what the constraint/limitation is
          2. Navigate to where it would manifest
          3. Test the edge case or boundary condition
          4. Document whether the constraint is:
             - CONFIRMED: Behaves as described
             - NOT REPRODUCIBLE: Could not trigger the behavior
             - DIFFERENT: Behaves differently than described
          5. Take screenshot as evidence

          ### When execution_order says "DOCUMENTATION":
          Capture screenshots of:
          - Main feature landing page
          - List/table views
          - Create/edit forms
          - Detail views
          - Settings/configuration pages
          - Any error states encountered
          - Approval flows (if present)
          - Workflow integration points (if present)

          ---

          ## NAVIGATION RULES

          **IMPORTANT: Stay within the application!**
          - Only navigate within app.bayzat.com
          - Do NOT click links that go to external sites (zendesk, help center, etc.)
          - Do NOT open new tabs to external URLs
          - If you accidentally navigate away, use browser_navigate_back to return

          **CRITICAL: Navigate by CLICKING, not by URL!**
          - NEVER use browser_navigate to go to internal pages (e.g., /payroll, /time, /leave-salary)
          - ALWAYS click on menu items, sidebar links, and navigation elements
          - The only time to use browser_navigate is for the initial login page
          - Many routes return 404 when accessed directly - they MUST be reached via UI clicks

          **SIDEBAR NAVIGATION TIPS:**
          - Take a snapshot first to see all menu items and their refs
          - Main menu items are usually in the left sidebar
          - Some items have submenus - click the parent first, wait 2 sec, then click the child
          - If a click doesn't navigate, wait 3 seconds and try again
          - After clicking, ALWAYS wait 3-5 seconds and take a snapshot to confirm navigation

          **SESSION HEALTH CHECKS:**
          - If you suddenly see the login page, your session expired - re-login
          - If navigation stops working, take a snapshot to diagnose
          - If the page seems frozen, wait 10 seconds then take a snapshot

          ---

          ## SCREEN DOCUMENTATION PROTOCOL

          For EVERY screen/page you visit, document:

          **A. Visible Elements:**
          - Page title and breadcrumbs
          - Navigation elements (tabs, sidebar items, menu items)
          - Buttons (labels and states - enabled/disabled)
          - Form fields (text inputs, dropdowns, checkboxes, date pickers)
          - Tables (column headers, row actions, pagination)
          - Status indicators and badges
          - Empty states and placeholder text

          **B. Interactive Element Exploration:**
          For each button/link:
          - What it's labeled
          - Whether it's clickable or disabled
          - What happens when clicked
          - Any confirmation dialogs

          **C. Form Field Documentation:**
          For each form field:
          - Field label and placeholder
          - Required or optional
          - Input type
          - Available options (for dropdowns)
          - Validation rules and error messages
          - Default values

          ---

          ## TIMEOUT PREVENTION

          To avoid workflow timeout (60 min limit):
          - Be efficient with exploration - don't over-explore unrelated areas
          - After 150 turns, start wrapping up and prepare JSON output
          - After 200 turns, STOP exploring and output JSON immediately
          - If stuck on any step for more than 5 retries, skip it and document the blocker

          ---

          ## OUTPUT FORMAT - MANDATORY JSON RESPONSE

          **CRITICAL: You MUST output a JSON result wrapped in ```json code blocks.**

          At the end of your exploration, output:

          ```json
          {
            "validation_status": "completed | partial | blocked",
            "login_success": true,
            "login_method": "browser_fill_form",
            "tour_dismissal": {
              "method": "click_based",
              "tours_found": 2,
              "tours_dismissed": 2,
              "issues": []
            },
            "feature_accessible": true,
            "feature_info": {
              "name": "Feature Name",
              "slug": "feature-slug",
              "category": "category",
              "url": "/path/to/feature"
            },
            "execution_order_followed": ["list of steps completed"],
            "primary_entity_identified": {
              "name": "Entity name (e.g., 'Expense Claim')",
              "singular": "expense claim",
              "plural": "expense claims",
              "crud_tested": {
                "create": { "found": true, "trigger_used": "description", "result": "what happened" },
                "read": { "found": true, "trigger_used": "description", "result": "what happened" },
                "update": { "found": true, "trigger_used": "description", "result": "what happened" },
                "delete": { "found": true, "trigger_used": "description", "result": "what happened" }
              }
            },
            "exploration_journey": [
              {
                "screen_name": "Screen/Page Name",
                "url": "/path/to/screen",
                "screenshot": "screenshot-name.png",
                "what_i_went_through": "Navigation path to reach this screen",
                "what_i_came_across": "Elements and sections present",
                "what_i_saw": {
                  "page_structure": "Layout description",
                  "visible_elements": ["List of UI elements"],
                  "data_displayed": "What data was shown",
                  "empty_states": "Any empty states"
                },
                "actions_i_performed": [
                  {
                    "action": "What I did",
                    "target": "Which element",
                    "result": "What happened",
                    "screenshot_after": "screenshot.png"
                  }
                ]
              }
            ],
            "workflow_integration": {
              "checked": true,
              "enabled_in_payload": true,
              "triggers_found": ["list of triggers"],
              "actions_found": ["list of actions"],
              "screenshot": "workflow-screenshot.png"
            },
            "approval_flow": {
              "checked": true,
              "enabled_in_payload": true,
              "signals_detected": ["which detection_signals were found"],
              "approval_chain": "description of approval flow",
              "screenshot": "approval-screenshot.png"
            },
            "what_to_do_results": [
              {
                "task": "task from payload",
                "status": "completed | partial | blocked",
                "steps_taken": ["what was done"],
                "result": "outcome",
                "screenshots": ["screenshot.png"]
              }
            ],
            "what_to_watch_out_for_validated": [
              {
                "constraint": "constraint from payload",
                "validation_status": "confirmed | not_reproducible | different",
                "evidence": "what was observed",
                "screenshot": "screenshot.png"
              }
            ],
            "full_behavior_catalog": {
              "buttons": [{ "label": "", "location": "", "state": "", "action_result": "" }],
              "dropdowns": [{ "label": "", "options": [], "default_value": "" }],
              "form_fields": [{ "label": "", "type": "", "required": false, "placeholder": "", "validation": "" }],
              "tabs": [{ "label": "", "content_summary": "" }],
              "modals_dialogs": [{ "trigger": "", "title": "", "content": "", "actions": [] }],
              "tables": [{ "location": "", "columns": [], "row_actions": [] }],
              "filters": [{ "filter_name": "", "filter_type": "", "options": [] }]
            },
            "what_works": [{ "feature_aspect": "", "description": "", "user_benefit": "" }],
            "whats_not_working": [{ "issue": "", "symptoms": "", "impact": "" }],
            "session_health": {
              "login_attempts": 1,
              "session_losses": 0,
              "tour_dismissal_attempts": 2
            },
            "screenshots_taken": 0,
            "validation_timestamp": "ISO timestamp",
            "summary": "Comprehensive summary"
          }
          ```

          **TURN LIMIT WARNING:**
          - You have LIMITED turns (300 max). Be efficient!
          - After 150 turns, start wrapping up
          - After 200 turns, STOP and output JSON immediately
          - An incomplete exploration WITH JSON is better than complete exploration WITHOUT JSON

          PROMPT_HEADER

          cat >> "$PROMPT_FILE" << EOF

          ## CREDENTIALS
          - Base URL: $APP_BASE_URL
          - Username: $APP_USERNAME
          - Password: $APP_PASSWORD

          ## SCREENSHOTS DIRECTORY
          Save all screenshots to: $SCREENSHOTS_DIR

          ## FEATURE PAYLOAD
          $(cat "$PAYLOAD_FILE")

          ## BEGIN EXPLORATION
          Start with PHASE 0 (browser setup and login), then follow the execution_order from the payload.

          **EFFICIENCY REMINDERS:**
          - Use browser_fill_form for login (fills email AND password in ONE call)
          - Use CLICK-BASED tour dismissal (browser_evaluate is unreliable)
          - Wait sufficiently after page loads (6-8 seconds for React apps)
          - If something fails, wait and retry once before moving on
          - Check session health periodically (are you still logged in?)
          - Focus on the main feature workflows
          - ALWAYS end with the complete JSON result

          ## FINAL OUTPUT REMINDER - DO NOT SKIP

          When you finish exploring, you MUST output a JSON block. This is MANDATORY.

          \`\`\`json
          {
            "validation_status": "completed",
            "login_success": true,
            "login_method": "browser_fill_form",
            "tour_dismissal": { "method": "click_based", "tours_dismissed": 2 },
            "feature_accessible": true,
            "feature_info": { ... },
            "execution_order_followed": [ ... ],
            "primary_entity_identified": { ... },
            "exploration_journey": [ ... ],
            "session_health": { "login_attempts": 1, "session_losses": 0 },
            "screenshots_taken": 16,
            "summary": "Your comprehensive summary here"
          }
          \`\`\`

          **The JSON block is MANDATORY. Without it, the workflow fails and your work is lost.**
          EOF

          echo "Starting Playwright validation for: $FEATURE_NAME"
          echo "============================================"

          # Create MCP config file (avoid shell escaping issues)
          MCP_CONFIG_FILE=$(mktemp)
          cat > "$MCP_CONFIG_FILE" << 'MCPCONFIG'
          {
            "mcpServers": {
              "playwright": {
                "command": "npx",
                "args": ["@executeautomation/playwright-mcp-server"],
                "env": {
                  "HEADLESS": "false",
                  "BROWSER": "chrome",
                  "VIEWPORT_WIDTH": "1280",
                  "VIEWPORT_HEIGHT": "900"
                }
              }
            }
          }
          MCPCONFIG

          # Run Claude Code with Playwright MCP (pipe prompt via stdin)
          cat "$PROMPT_FILE" | npx @anthropic-ai/claude-code@latest \
            --print \
            --dangerously-skip-permissions \
            --max-turns 300 \
            --mcp-config "$MCP_CONFIG_FILE" \
            2>&1 | tee "$RESULT_FILE.raw"

          # Extract JSON result from output using proper balanced brace parsing
          if [ -f "$RESULT_FILE.raw" ]; then
            PYEXTRACT_SCRIPT=$(mktemp)
            cat > "$PYEXTRACT_SCRIPT" << 'PYEOF'
          import sys
          import re
          import json

          raw_file = sys.argv[1]
          out_file = sys.argv[2]

          with open(raw_file, 'r', errors='ignore') as f:
              content = f.read()

          def extract_json_objects(text):
              """Extract JSON objects using balanced brace matching."""
              results = []
              i = 0
              while i < len(text):
                  if text[i] == '{':
                      depth = 0
                      start = i
                      in_string = False
                      escape_next = False
                      while i < len(text):
                          char = text[i]
                          if escape_next:
                              escape_next = False
                          elif char == '\\' and in_string:
                              escape_next = True
                          elif char == '"' and not escape_next:
                              in_string = not in_string
                          elif not in_string:
                              if char == '{':
                                  depth += 1
                              elif char == '}':
                                  depth -= 1
                                  if depth == 0:
                                      candidate = text[start:i+1]
                                      try:
                                          obj = json.loads(candidate)
                                          if isinstance(obj, dict) and any(k in obj for k in ['validation_status', 'exploration_journey', 'feature_info', 'login_success']):
                                              results.append((len(candidate), obj))
                                      except json.JSONDecodeError:
                                          pass
                                      break
                          i += 1
                  i += 1
              return results

          json_blocks = re.findall(r'```json\s*([\s\S]*?)\s*```', content)
          for block in reversed(json_blocks):
              try:
                  parsed = json.loads(block)
                  if isinstance(parsed, dict) and any(k in parsed for k in ['validation_status', 'exploration_journey', 'feature_info']):
                      with open(out_file, 'w') as f:
                          json.dump(parsed, f, indent=2)
                      print(f"Extracted JSON from code block ({len(block)} chars)")
                      sys.exit(0)
              except json.JSONDecodeError:
                  continue

          json_objects = extract_json_objects(content)
          if json_objects:
              largest = max(json_objects, key=lambda x: x[0])
              with open(out_file, 'w') as f:
                  json.dump(largest[1], f, indent=2)
              print(f"Extracted JSON using brace matching ({largest[0]} chars)")
              sys.exit(0)

          all_objects = []
          i = 0
          while i < len(content):
              if content[i] == '{':
                  for j in range(len(content) - 1, i, -1):
                      if content[j] == '}':
                          try:
                              candidate = content[i:j+1]
                              obj = json.loads(candidate)
                              if isinstance(obj, dict) and len(obj) > 3:
                                  all_objects.append((len(candidate), obj))
                              break
                          except:
                              continue
              i += 1

          if all_objects:
              largest = max(all_objects, key=lambda x: x[0])
              with open(out_file, 'w') as f:
                  json.dump(largest[1], f, indent=2)
              print(f"Extracted JSON using fallback method ({largest[0]} chars)")
              sys.exit(0)

          with open(out_file, 'w') as f:
              json.dump({
                  "error": "Could not extract valid JSON from output",
                  "raw_length": len(content),
                  "json_blocks_found": len(json_blocks),
                  "hint": "The Claude output may not have included a properly formatted JSON result"
              }, f, indent=2)
          print("WARNING: Could not extract JSON, wrote error file")
          PYEOF
            python3 "$PYEXTRACT_SCRIPT" "$RESULT_FILE.raw" "$RESULT_FILE"
            rm -f "$PYEXTRACT_SCRIPT"
          fi

          # Cleanup temp files
          rm -f "$MCP_CONFIG_FILE" "$PROMPT_FILE"

          echo "============================================"
          echo "Validation complete"

      - name: Merge Payload Data into Result
        if: steps.detect.outputs.skip != 'true'
        run: |
          PAYLOAD_FILE="${{ steps.detect.outputs.payload_file }}"
          RESULT_FILE="${{ steps.dirs.outputs.result_file }}"

          echo "Merging payload data into result.json..."

          # Merge what_to_watch_out_for, what_to_do, feature_info from payload into result
          PYMERGE_SCRIPT=$(mktemp)
          cat > "$PYMERGE_SCRIPT" << 'PYEOF'
          import sys
          import json

          payload_file = sys.argv[1]
          result_file = sys.argv[2]

          try:
              with open(payload_file, 'r') as f:
                  payload_data = json.load(f)
                  if isinstance(payload_data, list) and len(payload_data) > 0:
                      payload_data = payload_data[0]
          except Exception as e:
              print(f"Warning: Could not load payload: {e}")
              payload_data = {}

          try:
              with open(result_file, 'r') as f:
                  result_data = json.load(f)
          except Exception as e:
              print(f"Warning: Could not load result: {e}")
              result_data = {}

          playwright_context = payload_data.get('playwright_context', {})

          what_to_watch_out_for = (
              playwright_context.get('what_to_watch_out_for') or
              payload_data.get('what_to_watch_out_for') or
              []
          )

          what_to_do = (
              playwright_context.get('what_to_do') or
              payload_data.get('what_to_do') or
              []
          )

          feature_info = (
              payload_data.get('feature_info') or
              playwright_context.get('feature_metadata') or
              {}
          )

          detected_integrations = (
              payload_data.get('detected_integrations') or
              playwright_context.get('detected_integrations') or
              {}
          )

          result_data['payload_context'] = {
              'what_to_watch_out_for': what_to_watch_out_for,
              'what_to_do': what_to_do,
              'feature_info': feature_info,
              'detected_integrations': detected_integrations,
              'limitations_count': len(what_to_watch_out_for),
              'tasks_count': len(what_to_do)
          }

          if what_to_watch_out_for and 'what_to_watch_out_for' not in result_data:
              result_data['what_to_watch_out_for'] = what_to_watch_out_for

          if what_to_do and 'what_to_do' not in result_data:
              result_data['what_to_do'] = what_to_do

          with open(result_file, 'w') as f:
              json.dump(result_data, f, indent=2)

          print(f"Merged payload data into result:")
          print(f"  - what_to_watch_out_for: {len(what_to_watch_out_for)} items")
          print(f"  - what_to_do: {len(what_to_do)} tasks")
          print(f"  - feature_info: {feature_info.get('feature_name', 'unknown')}")
          PYEOF
          python3 "$PYMERGE_SCRIPT" "$PAYLOAD_FILE" "$RESULT_FILE"
          rm -f "$PYMERGE_SCRIPT"

      - name: Generate Report
        if: steps.detect.outputs.skip != 'true'
        run: |
          FOLDER="${{ steps.detect.outputs.folder }}"
          FEATURE_NAME="${{ steps.detect.outputs.feature_name }}"
          FEATURE_SLUG="${{ steps.detect.outputs.feature_slug }}"
          RESULT_FILE="${{ steps.dirs.outputs.result_file }}"
          REPORT_FILE="${{ steps.dirs.outputs.report_file }}"
          SCREENSHOTS_DIR="${{ steps.dirs.outputs.screenshots_dir }}"

          # Start report - write header
          {
            echo "# Validation Report: ${FEATURE_NAME}"
            echo ""
            echo "**Generated**: $(date -u +%Y-%m-%dT%H:%M:%SZ)"
            echo "**Run ID**: ${{ github.run_id }}"
            echo ""
            echo "## Result"
            echo ""
            echo '```json'
            cat "$RESULT_FILE" 2>/dev/null || echo '{"error": "No result file generated"}'
            echo '```'
            echo ""
            echo "## Screenshots"
            echo ""
          } > "$REPORT_FILE"

          # Add screenshots as markdown image links
          if [ -d "$SCREENSHOTS_DIR" ] && [ "$(ls -A "$SCREENSHOTS_DIR" 2>/dev/null)" ]; then
            SCREENSHOT_COUNT=0
            for img in "$SCREENSHOTS_DIR"/*.png; do
              if [ -f "$img" ]; then
                filename=$(basename "$img")
                # Create a readable title from filename
                title=$(echo "$filename" | sed 's/\.png$//' | sed 's/-/ /g' | sed 's/_/ /g')
                echo "### ${title}" >> "$REPORT_FILE"
                echo "" >> "$REPORT_FILE"
                echo "![${filename}](screenshots/${filename})" >> "$REPORT_FILE"
                echo "" >> "$REPORT_FILE"
                SCREENSHOT_COUNT=$((SCREENSHOT_COUNT + 1))
              fi
            done
            echo "" >> "$REPORT_FILE"
            echo "**Total screenshots captured**: ${SCREENSHOT_COUNT}" >> "$REPORT_FILE"
          else
            echo "No screenshots were captured during validation." >> "$REPORT_FILE"
          fi

          echo "Report generated: $REPORT_FILE"

      - name: Commit Results
        if: steps.detect.outputs.skip != 'true'
        env:
          PAT_TOKEN: ${{ secrets.PAT_TOKEN }}
        run: |
          FOLDER="${{ steps.detect.outputs.folder }}"
          FEATURE_NAME="${{ steps.detect.outputs.feature_name }}"

          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"
          git remote set-url origin "https://x-access-token:${PAT_TOKEN}@github.com/${{ github.repository }}"

          git add "$FOLDER/validation/" || true
          git commit -m "validation: $FEATURE_NAME exploration results" || echo "No changes to commit"
          git push || echo "Push failed"

      - name: Notify n8n
        if: always() && steps.detect.outputs.skip != 'true'
        run: |
          curl -s -X POST "https://automation-wh.bayzat.com/webhook/validation-complete" \
            -H "Content-Type: application/json" \
            -d '{
              "feature_folder": "${{ steps.detect.outputs.folder }}",
              "feature_name": "${{ steps.detect.outputs.feature_name }}",
              "status": "${{ job.status }}",
              "run_id": "${{ github.run_id }}",
              "run_url": "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
            }' || echo "Webhook notification failed (non-blocking)"
